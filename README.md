
ğŸš€ ì‹œìŠ¤í…œ ê°œìš”: ë°ì´í„° ì²˜ë¦¬ ë° ê²€ìƒ‰ íë¦„
-
ì €í¬ ì‹œìŠ¤í…œì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ í†µí•©í•˜ê³ , ì´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆì˜ì— ì •í™•í•˜ê²Œ ì‘ë‹µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ í¬ê²Œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬, ê·¸ë¦¬ê³  ë°ì´í„° ê²€ìƒ‰ ë° ë²¡í„°í™”ë‹¨ê³„ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.

ğŸ› ï¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
-
load_specific_tour_data í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ CSV íŒŒì¼ì— ë¶„ì‚°ëœ ê´€ê´‘ì§€ ì •ë³´ë¥¼ í†µí•©í•˜ê³ , í•„ìš”í•œ í˜•íƒœë¡œ ì •ì œí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. @st.cache_data ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Streamlit ì•±ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.


@st.cache_data
def load_specific_tour_data(file_paths_list):
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ë¡œë“œí•˜ê³ , ëª¨ë“  íŒŒì¼ì— CP949 ì¸ì½”ë”©ì„ ì ìš©í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤."""
    combined_df = pd.DataFrame()

    if not file_paths_list:
        st.error("ë¡œë“œí•  ê´€ê´‘ì§€ CSV íŒŒì¼ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    for file_path in file_paths_list:
        if not os.path.exists(file_path):
            st.warning(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤. (Streamlit Cloudì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ë“¤ì´ Git ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")
            continue

        # 'cp494' ì˜¤ë¥˜ ìˆ˜ì •: 'cp949'ë¡œ ë³€ê²½
        current_encoding = 'cp949'  

        try:
            # GitHubì— íŒŒì¼ì´ ìˆë‹¤ë©´, Streamlitì€ í•´ë‹¹ ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
            df = pd.read_csv(file_path, encoding=current_encoding)
            df.columns = df.columns.str.strip()

            if "ìœ„ë„" not in df.columns or "ê²½ë„" not in df.columns:
                st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ì€ 'ìœ„ë„', 'ê²½ë„' ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
                continue

            name_col = None
            for candidate in ["ê´€ê´‘ì§€ëª…", "ê´€ê´‘ì •ë³´ëª…","ê´€ê´‘ì§€"]:
                if candidate in df.columns:
                    name_col = candidate
                    break

            if name_col is None:
                df["ê´€ê´‘ì§€ëª…"] = "ì´ë¦„ ì—†ìŒ"
            else:
                df["ê´€ê´‘ì§€ëª…"] = df[name_col]

            address_col = None
            for candidate in ["ì •ì œë„ë¡œëª…ì£¼ì†Œ","ì •ì œì§€ë²ˆì£¼ì†Œ","ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ","ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]:
                if candidate in df.columns:
                    address_col = candidate
                    break

            if address_col is None:
                df["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = "ì£¼ì†Œ ì—†ìŒ"
            else:
                df["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = df[address_col]

            df = df[["ìœ„ë„", "ê²½ë„", "ê´€ê´‘ì§€ëª…", "ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]]

            combined_df = pd.concat([combined_df, df], ignore_index=True)

        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if combined_df.empty:
        st.error("ì§€ì •ëœ íŒŒì¼ë“¤ì—ì„œ ìœ íš¨í•œ ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ì™€ íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    return combined_df
ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
-
**CSV íŒŒì¼ í†µí•©:**
file_paths_listì— ëª…ì‹œëœ ì—¬ëŸ¬ CSV íŒŒì¼ì„ CP949 ì¸ì½”ë”©ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
**ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬**: ê° íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì¸ ìœ„ë„ì™€ ê²½ë„ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
**ì»¬ëŸ¼ í‘œì¤€í™”**: ê´€ê´‘ì§€ëª…ê³¼ ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œì™€ ê°™ì´ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ì´ë¦„ì´ ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ì„ í‘œì¤€í™”í•˜ì—¬ ë°ì´í„° ì¼ê´€ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.
**ì˜¤ë¥˜ ì²˜ë¦¬**: íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ê³  í•´ë‹¹ íŒŒì¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.
**ìºì‹±**: @st.cache_data ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìºì‹±í•˜ë¯€ë¡œ, ë°ì´í„°ê°€ ë³€ê²½ë˜ì§€ ì•ŠëŠ” í•œ ë¶ˆí•„ìš”í•œ ì¬ë¡œë”©ì„ ë°©ì§€í•˜ì—¬ ì•±ì˜ ë¡œë”© ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤

ğŸ” ë°ì´í„° ê²€ìƒ‰ ë° ë²¡í„°í™” (Retrieval)
-
ì´ ì„¹ì…˜ì—ì„œëŠ” RAG(Retrieval Augmented Generation) ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ CSV íŒŒì¼ì— ë¶„ì‚°ëœ ê´€ê´‘ì§€ ì •ë³´ë¥¼ í†µí•©í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ëŠ” LLM(Large Language Model)ì´ ë‹¨ìˆœíˆ í•™ìŠµëœ ì§€ì‹ì— ì˜ì¡´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ë‹¨ê³„ì…ë‹ˆë‹¤.

**1. ë‹¤ì–‘í•œ CSV íŒŒì¼ í†µí•© ë° ë²¡í„°í™”**
ê²½ê¸°ë„ì—­ì‚¬ê´€ê´‘ì§€í˜„í™©.csv, ê²½ê¸°ë„ìì—°ê´€ê´‘ì§€í˜„í™©.csv ë“± ì—¬ëŸ¬ CSV íŒŒì¼ì— í©ì–´ì§„ ë°©ëŒ€í•œ ê´€ê´‘ì§€ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤.

CSVLoader: LangChainì˜ CSVLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ê° CSV íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì´ë•Œ, cp949 ì¸ì½”ë”©ì„ ì ìš©í•˜ì—¬ í•œê¸€ ë°ì´í„° ì²˜ë¦¬ì˜ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.
RecursiveCharacterTextSplitter: ë¡œë“œëœ ë¬¸ì„œëŠ” RecursiveCharacterTextSplitterë¥¼ ì´ìš©í•´ ì¼ì •í•œ í¬ê¸°(chunk_size=250, chunk_overlap=50)ë¡œ ë¶„í• ë©ë‹ˆë‹¤. ì´ëŠ” ë¬¸ì„œì˜ ë‚´ìš©ì„ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ ë²¡í„°í™”ì— ì í•©í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤.
ë°ì´í„° ì„ë² ë”©: ì´ ê³¼ì •ì„ í†µí•´ ê´€ê´‘ì§€ ë°ì´í„°ê°€ ë²¡í„° ê³µê°„ì— ì„ë² ë”©ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤.
**2. FAISSë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ì •ë³´ ê²€ìƒ‰**
FAISSëŠ” ëŒ€ê·œëª¨ ë²¡í„° ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆì˜ê°€ ë“¤ì–´ì˜¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë™í•©ë‹ˆë‹¤.

ì§ˆì˜ ë²¡í„° ë³€í™˜: ì‚¬ìš©ìì˜ ì§ˆì˜ ë˜í•œ OpenAI ì„ë² ë”©ì„ í†µí•´ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
ì˜ë¯¸ì  ê´€ë ¨ì„± ê²€ìƒ‰: ë³€í™˜ëœ ì§ˆì˜ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ FAISS ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ê´€ê´‘ì§€ ì •ë³´(context)ë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
      

ğŸ“¦ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ë° ìºì‹±
-
ì•„ë˜ ì½”ë“œëŠ” ê´€ê´‘ì§€ ì •ë³´ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ì¥í•˜ê³ , í•„ìš”í•  ë•Œ ë¹ ë¥´ê²Œ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
load_and_create_vectorstore_from_specific_files í•¨ìˆ˜
ì´ í•¨ìˆ˜ëŠ” ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

@st.cache_resource
def load_and_create_vectorstore_from_specific_files(tour_csv_files_list):
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    all_city_tour_docs = []
    for file_path in tour_csv_files_list:
        if not os.path.exists(file_path):
            st.warning(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì„ ìœ„í•´ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
            continue

        current_encoding = 'cp949'  

        try:
            city_tour_loader = CSVLoader(file_path=file_path, encoding=current_encoding, csv_args={'delimiter': ','})
            all_city_tour_docs.extend(city_tour_loader.load())
        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë²¡í„°ìŠ¤í† ì–´): {e}")

    all_documents = all_city_tour_docs

    if not all_documents:
        st.error("ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)
    docs = text_splitter.split_documents(all_documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(VECTOR_DB_PATH)
    return vectorstore


ì½”ë“œ ë¶€ë¶„:Python
ì´ ì½”ë“œëŠ” CSV íŒŒì¼ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ì´ë¥¼ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¡œ ì²˜ë¦¬í•œ ë’¤, OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°í™”í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ FAISS ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. get_vectorstore_cached í•¨ìˆ˜ëŠ” ì´ë¯¸ ìƒì„±ëœ ë²¡í„° DBê°€ ìˆë‹¤ë©´ ì´ë¥¼ ë¡œë“œí•˜ì—¬ ë¶ˆí•„ìš”í•œ ì¬êµ¬ì¶•ì„ ë§‰ì•„ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤


@st.cache_resource()
def get_vectorstore_cached(tour_csv_files_list):
    """ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    if os.path.exists(VECTOR_DB_PATH):
        try:
            return FAISS.load_local(
                VECTOR_DB_PATH,
                OpenAIEmbeddings(),
                allow_dangerous_deserialization=True
            )
        except Exception as e:
            st.warning(f"ê¸°ì¡´ ë²¡í„° DB ë¡œë”© ì‹¤íŒ¨: {e}. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            return load_and_create_vectorstore_from_specific_files(tour_csv_files_list)
    else:
        return load_and_create_vectorstore_from_specific_files(tour_csv_files_list)


# --- Haversine distance function ---
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Radius of Earth in kilometers
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    distance = R * c
    return distance

# --- 3. ì‚¬ìš©ì ì…ë ¥ ë° UI ë¡œì§ í•¨ìˆ˜ ---
def get_user_inputs_ui():
    """ì‚¬ìš©ìë¡œë¶€í„° ë‚˜ì´, ì—¬í–‰ ìŠ¤íƒ€ì¼, í˜„ì¬ ìœ„ì¹˜, ê·¸ë¦¬ê³  ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´ë¥¼ ì…ë ¥ë°›ëŠ” UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("#### ì‚¬ìš©ì ì •ë³´ ì…ë ¥")
        # 'ë‚˜ì´ëŒ€ ì„ íƒ' selectboxì˜ ë„ˆë¹„ë¥¼ CSSë¡œ ì¡°ì ˆí•˜ê¸° ìœ„í•´ keyë¥¼ ë¶€ì—¬
        age = st.selectbox("ë‚˜ì´ëŒ€ ì„ íƒ", ["10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€ ì´ìƒ"], key='age_selectbox_new')
        travel_style = st.multiselect("ì—¬í–‰ ìŠ¤íƒ€ì¼", ["ìì—°", "ì—­ì‚¬", "ì²´í—˜", "íœ´ì‹", "ë¬¸í™”", "ê°€ì¡±", "ì•¡í‹°ë¹„í‹°"], key='travel_style_multiselect')

    st.header("â‘  ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°")
    location = streamlit_geolocation()

    user_lat_final, user_lon_final = None, None

    if location and "latitude" in location and "longitude" in location:
        temp_lat = location.get("latitude")
        temp_lon = location.get("longitude")
        if temp_lat is not None and temp_lon is not None:
            user_lat_final = temp_lat
            user_lon_final = temp_lon
            st.success(f"ğŸ“ í˜„ì¬ ìœ„ì¹˜: ìœ„ë„ {user_lat_final:.7f}, ê²½ë„ {user_lon_final:.7f}")
        else:
            st.warning("ğŸ“ ìœ„ì¹˜ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("ìœ„ì¹˜ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìœ„ë„, ê²½ë„ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    if user_lat_final is None or user_lon_final is None:
        default_lat = st.session_state.get("user_lat", 37.5665) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ìœ„ë„
        default_lon = st.session_state.get("user_lon", 126.9780) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ê²½ë„

        st.subheader("ì§ì ‘ ìœ„ì¹˜ ì…ë ¥ (ì„ íƒ ì‚¬í•­)")
        manual_lat = st.number_input("ìœ„ë„", value=float(default_lat), format="%.7f", key="manual_lat_input")
        manual_lon = st.number_input("ê²½ë„", value=float(default_lon), format="%.7f", key="manual_lon_input")

        if manual_lat != 0.0 or manual_lon != 0.0:
            user_lat_final = manual_lat
            user_lon_final = manual_lon
        else:
            user_lat_final = None
            user_lon_final = None
            st.error("ìœ íš¨í•œ ìœ„ë„ ë° ê²½ë„ ê°’ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 0ì´ ì•„ë‹Œ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.session_state.user_lat = user_lat_final
    st.session_state.user_lon = user_lon_final

    st.markdown("#### ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´")
    trip_duration_days = st.number_input("ì—¬í–‰ ê¸°ê°„ (ì¼)", min_value=1, value=3, key='trip_duration')
    estimated_budget = st.number_input("ì˜ˆìƒ ì˜ˆì‚° (ì›, ì´ ê¸ˆì•¡)", min_value=0, value=500000, step=10000, key='estimated_budget')
    num_travelers = st.number_input("ì—¬í–‰ ì¸ì› (ëª…)", min_value=1, value=2, key='num_travelers')
    special_requests = st.text_area("íŠ¹ë³„íˆ ê³ ë ¤í•  ì‚¬í•­ (ì„ íƒ ì‚¬í•­)", help="ì˜ˆ: ìœ ëª¨ì°¨ ì‚¬ìš©, ê³ ë ¹ì ë™ë°˜, íŠ¹ì • ìŒì‹ ì„ í˜¸ ë“±", key='special_requests')

    return age, travel_style, user_lat_final, user_lon_final, trip_duration_days, estimated_budget, num_travelers, special_requests
    
ì´ ì½”ë“œëŠ” RAGì˜ í•µì‹¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆì˜ì™€ í•¨ê»˜ ê²€ìƒ‰ëœ ë¬¸ì„œ (context) ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì‚¬ìš©ì ì…ë ¥(age, travel_style, user_lat, user_lon ë“±)ì„ í¬í•¨í•˜ëŠ” ë™ì ì¸ í”„ë¡¬í”„íŠ¸ê°€ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLM (gpt-4o)ì´ ë‹¨ìˆœí•œ ì¼ë°˜ ì§€ì‹ ë‹µë³€ì„ ë„˜ì–´, ì‚¬ìš©ìì˜ íŠ¹ì„±ê³¼ ê²€ìƒ‰ëœ ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤. search_kwargs={"k": 15}ëŠ” ê²€ìƒ‰ ì‹œ ê°€ì¥ ìœ ì‚¬í•œ 15ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •í•˜ì—¬, LLMì´ ë” í’ë¶€í•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

# --- 4. ì¶”ì²œ ë¡œì§ í•¨ìˆ˜ (Langchain API ë³€ê²½: create_retrieval_chain ì‚¬ìš©) (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •) ---
@st.cache_resource
def get_qa_chain(_vectorstore):
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)

    qa_prompt = PromptTemplate.from_template(
        """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œ ë° ìƒì„¸ ì—¬í–‰ ê³„íš ìˆ˜ë¦½ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë‚˜ì´ëŒ€, ì—¬í–‰ ì„±í–¥, í˜„ì¬ ìœ„ì¹˜ ì •ë³´, ê·¸ë¦¬ê³  ë‹¤ìŒì˜ ì¶”ê°€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ ì£¼ì„¸ìš”.
**ê´€ê´‘ì§€ ì¶”ì²œ ì‹œ ì‚¬ìš©ì ìœ„ì¹˜ë¡œë¶€í„°ì˜ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ë‹µë³€ì—ì„œ ê±°ë¦¬ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
íŠ¹íˆ, ì‚¬ìš©ìì˜ í˜„ì¬ ìœ„ì¹˜({user_lat}, {user_lon})ì—ì„œ ê°€ê¹Œìš´ ì¥ì†Œë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•˜ê³  ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.
ê¼­ê¼­ ì‚¬ìš©ì í˜„ì¬ ìœ„ì¹˜ì™€ ê°€ê¹Œìš´ ê³³ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì£¼ê³  ì‚¬ìš©ìê°€ ì„ íƒí•œ ì„±í–¥ì— ë§ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

[ê´€ê´‘ì§€ ë°ì´í„°]
{context}

[ì‚¬ìš©ì ì •ë³´]
ë‚˜ì´ëŒ€: {age}
ì—¬í–‰ ì„±í–¥: {travel_style}
í˜„ì¬ ìœ„ì¹˜ (ìœ„ë„, ê²½ë„): {user_lat}, {user_lon}
ì—¬í–‰ ê¸°ê°„: {trip_duration_days}ì¼
ì˜ˆìƒ ì˜ˆì‚°: {estimated_budget}ì›
ì—¬í–‰ ì¸ì›: {num_travelers}ëª…
íŠ¹ë³„ ê³ ë ¤ì‚¬í•­: {special_requests}

[ì‚¬ìš©ì ì§ˆë¬¸]
{input}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”:
1.  **ê´€ê´‘ì§€ ì¶”ì²œ:** ì§ˆë¬¸ì— ë¶€í•©í•˜ê³ , ì‚¬ìš©ì ìœ„ì¹˜ì—ì„œ ê°€ê¹Œìš´ 1~3ê°œì˜ ì£¼ìš” ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ê° ê´€ê´‘ì§€ì— ëŒ€í•œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
    * ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª…]
    * ì£¼ì†Œ: [ì£¼ì†Œ]
    * ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´]
    **[ì°¸ê³ : ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ì´ í•­ëª©ì€ ì œì™¸í•©ë‹ˆë‹¤.]**
    
2.  **ì¶”ì²œëœ ê´€ê´‘ì§€ë¥¼ í¬í•¨í•˜ì—¬, ì‚¬ìš©ì ì •ë³´ì™€ ì§ˆë¬¸ì— ê¸°ë°˜í•œ {trip_duration_days}ì¼ê°„ì˜ ìƒì„¸ ì—¬í–‰ ê³„íšì„ ì¼ìë³„ë¡œ êµ¬ì„±í•´ ì£¼ì„¸ìš”.**
    * ê° ë‚ ì§œë³„ë¡œ ë°©ë¬¸í•  ì¥ì†Œ(ì‹ë‹¹, ì¹´í˜, ê¸°íƒ€ í™œë™ í¬í•¨), ì˜ˆìƒ ì‹œê°„, ê°„ë‹¨í•œ í™œë™ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
    * ì˜ˆì‚°ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì‹ì‚¬ ì¥ì†Œë‚˜ í™œë™ì„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * ì´ë™ ê²½ë¡œ(ì˜ˆ: "ë„ë³´ 15ë¶„", "ë²„ìŠ¤ 30ë¶„")ë¥¼ ê°„ëµí•˜ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.
    * ê³„íšì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

[ë‹µë³€ ì˜ˆì‹œ]
**ì¶”ì²œ ê´€ê´‘ì§€:**
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 1]
  - ì£¼ì†Œ: [ì£¼ì†Œ 1]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 1]
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 2]
  - ì£¼ì†Œ: [ì£¼ì†Œ 2]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 2]

**ìƒì„¸ ì—¬í–‰ ê³„íš ({trip_duration_days}ì¼):**
ë‹¤ìŒ í‘œ í˜•ì‹ìœ¼ë¡œ ì¼ìë³„ ìƒì„¸ ê³„íšì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì»¬ëŸ¼ëª…ì€ 'ì¼ì°¨', 'ì‹œê°„', 'í™œë™', 'ì˜ˆìƒ ì¥ì†Œ', 'ì´ë™ ë°©ë²•'ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
| ì¼ì°¨ | ì‹œê°„ | í™œë™ | ì˜ˆìƒ ì¥ì†Œ | ì´ë™ ë°©ë²• |
|---|---|---|---|---|
| 1ì¼ì°¨ | ì˜¤ì „ (9:00 - 12:00) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª…] | [ì´ë™ ë°©ë²•] |
| 1ì¼ì°¨ | ì ì‹¬ (12:00 - 13:00) | [ì‹ì‚¬] | [ì‹ë‹¹ëª…] | - |
| 1ì¼ì°¨ | ì˜¤í›„ (13:00 - 17:00) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª…] | [ì´ë™ ë°©ë²•] |
| 1ì¼ì°¨ | ì €ë… (17:00 ì´í›„) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª… ë˜ëŠ” ììœ  ì‹œê°„] | - |
| 2ì¼ì°¨ | ... | ... | ... | ... |
**ì¤‘ìš”: 'ì¼ì°¨' ì»¬ëŸ¼ì˜ ê²½ìš°, ê°™ì€ ì¼ì°¨ì˜ ì—¬ëŸ¬ í™œë™ì´ ìˆì„ ê²½ìš° ì²« ë²ˆì§¸ í™œë™ì—ë§Œ í•´ë‹¹ 'ì¼ì°¨'ë¥¼ ëª…ì‹œí•˜ê³ , ë‚˜ë¨¸ì§€ í™œë™ í–‰ì˜ 'ì¼ì°¨' ì…€ì€ ë¹„ì›Œë‘ì„¸ìš” (ì˜ˆ: "| | ì‹œê°„ | í™œë™ | ì˜ˆìƒ ì¥ì†Œ | ì´ë™ ë°©ë²• |"). ì´ë ‡ê²Œ í•´ì•¼ í‘œì—ì„œ 'ì¼ì°¨'ê°€ ìë™ìœ¼ë¡œ ë³‘í•©ë˜ì–´ ë³´ì…ë‹ˆë‹¤.**
"""
    )
    document_chain = create_stuff_documents_chain(llm, qa_prompt)
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 15})
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain


